%%% Referências oficiais

@incollection{vapnik2006semi,
  author =       "Vladimir Vapnik",
  title =        "Transductive Inference and Semi-Supervised Learning",
  editor =       {Chapelle, O. and Sch\"olkopf, B. and Zien, A. and
                  others},
  booktitle =    {Semi-supervised Learning},
  publisher =    {MIT press Cambridge},
  address =      "MIT",
  year =         2006,
  pages =        "468-487",
  chapter =      24,
}

@InProceedings{MartinFTM01,
  author =       {D. Martin and C. Fowlkes and D. Tal and J. Malik},
  title =        {A Database of Human Segmented Natural Images and its
                  Application to Evaluating Segmentation Algorithms
                  and Measuring Ecological Statistics},
  booktitle =    {Proc. 8th Int'l Conf. Computer Vision},
  year =         2001,
  month =        {July},
  volume =       2,
  pages =        {416--423}
}

@online{MediumInstanceSegmentation2019,
    author = {Joinal Ahmed},
    title = {Instance Segmentation with Mask R-CNN and TensorFlow on Onepanel},
    year = 2019,
    url = {https://medium.com/onepanel/instance-segmentation-with-mask-r-cnn-and-tensorflow-on-onepanel-6a072a4273dd},
    urlaccessdate = {27 mar. 2021},
}

@InProceedings{DnayaMotivation,
  author =       {Verri, Filipe Alves Neto},
  title =        {Motivation of DNAYA Project},
  year =         2021,
  url =          {https://dnaya-org.github.io/fundamentals/motivation},
  urlaccessdate ={27 mar. 2021},
  note =         {Motivação sobre o projeto DNAYA, Redes Complexas e
                  Aprendizado de Máquina}
}

@article{ImageSegmentationTechniques1985,
  title =        {Image segmentation techniques},
  journal =      {Computer Vision, Graphics, and Image Processing},
  volume =       29,
  number =       1,
  pages =        {100-132},
  year =         1985,
  issn =         {0734-189X},
  doi =          {https://doi.org/10.1016/S0734-189X(85)90153-7},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0734189X85901537},
  author =       {Robert M. Haralick and Linda G. Shapiro},
  abstract =     {There are now a wide variety of image segmentation
                  techniques, some considered general purpose and some
                  designed for specific classes of images. These
                  techniques can be classified as: measurement space
                  guided spatial clustering, single linkage region
                  growing schemes, hybrid linkage region growing
                  schemes, centroid linkage region growing schemes,
                  spatial clustering schemes, and split-and-merge
                  schemes. In this paper, each of the major classes of
                  image segmentation techniques is defined and several
                  specific examples of each class of algorithm are
                  described. The techniques are illustrated with
                  examples of segmentations performed on real images.}
}

@misc{he2018mask,
  title =        {Mask R-CNN},
  author =       {Kaiming He and Georgia Gkioxari and Piotr Dollár and
                  Ross Girshick},
  year =         2018,
  eprint =       {1703.06870},
  archivePrefix ={arXiv},
  primaryClass = {cs.CV}
}

@INPROCEEDINGS{VerriRandomWalk2016,
  author =       {F. A. N. {Verri} and L. {Zhao}},
  booktitle =    {2016 5th Brazilian Conference on Intelligent Systems
                  (BRACIS)},
  title =        {Random Walk in Feature-Sample Networks for
                  Semi-supervised Classification},
  year =         2016,
  pages =        {235-240},
  doi =          {10.1109/BRACIS.2016.051}
}

@inproceedings{LuoSemiSupervised2021,
  title =        {Semi-supervised medical image segmentation through
                  dual-task consistency},
  author =       {Luo, Xiangde and Chen, Jieneng and Song, Tao and
                  Wang, Guotai},
  booktitle =    {Proceedings of the AAAI conference on artificial
                  intelligence},
  volume =       35,
  number =       10,
  pages =        {8801--8809},
  year =         2021
}

@misc{franciscolira2018,
  title =        {Aplicação de Agrupamento Semissupervisionado para
                  Segmentação de Imagens Coloridas},
  organization = {UFPE},
  author =       {Francisco Lira},
  url =
                  {http://www.bcc.ufrpe.br/sites/ww3.bcc.ufrpe.br/files/Francisco%20Lira.pdf},
  publisher =    {Universidade Federal do Pernambuco (UFPE)},
  year =         2018,
  archivePrefix ={respositorio.ufpe.br},
  primaryClass = {cs.CV}
}

@article{VerriNetworkUnfoldingMap2018,
  title =        {Network Unfolding Map by Vertex-Edge Dynamics
                  Modeling},
  volume =       29,
  ISSN =         {2162-2388},
  url =          {http://dx.doi.org/10.1109/TNNLS.2016.2626341},
  DOI =          {10.1109/tnnls.2016.2626341},
  number =       2,
  journal =      {IEEE Transactions on Neural Networks and Learning
                  Systems},
  publisher =    {Institute of Electrical and Electronics Engineers
                  (IEEE)},
  author =       {Verri, Filipe Alves Neto and Urio, Paulo Roberto and
                  Zhao, Liang},
  year =         2018,
  month =        {Feb},
  pages =        {405–418}
}

@article{SuperpixelSurvey2020,
  author =       {Ibrahim, Abdelhameed and El-kenawy, El-Sayed},
  year =         2020,
  month =        10,
  pages =        {1-10},
  title =        {Image Segmentation Methods Based on Superpixel
                  Techniques: A Survey},
  volume =       1
}

@article{SuperPixelBenchmark2017,
  title =        {Superpixel segmentation: A benchmark},
  journal =      {Signal Processing: Image Communication},
  volume =       56,
  pages =        {28-39},
  year =         2017,
  issn =         {0923-5965},
  doi =          {https://doi.org/10.1016/j.image.2017.04.007},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0923596517300735},
  author =       {Murong Wang and Xiabi Liu and Yixuan Gao and Xiao Ma
                  and Nouman Q. Soomro},
  keywords =     {Superpixel, Benchmark, Evaluation},
  abstract =     {Various superpixel approaches have been published
                  recently. These algorithms are assessed using
                  different evaluation metrics and datasets resulting
                  in discrepancy in algorithm comparison. This calls
                  for a benchmark to compare the state-of-the-arts
                  methods and evaluate their pros and cons. We analyze
                  benchmark metrics, datasets and built a superpixel
                  benchmark. We evaluated and integrated top 15
                  superpixel algorithms, whose code are publicly
                  available, into one code library and, provide a
                  quantitative comparison of these algorithms. We find
                  that some superpixel algorithms perform consistently
                  better than others. Clustering based superpixel
                  algorithms are more efficient than graph-based
                  ones. Furthermore, we also introduced a novel metric
                  to evaluate superpixel regularity, which is a
                  property that superpixels desired. The evaluation
                  results demonstrate the performance and limitations
                  of state-of-the-art algorithms. Our evaluation and
                  observations give deep insight about different
                  algorithms and will help researchers to identify the
                  more feasible superpixel segmentation methods for
                  their different problems.}
}

@article{JarbasComplexNetworks2020,
  title =        {Fusion of complex networks and randomized neural
                  networks for texture analysis},
  journal =      {Pattern Recognition},
  volume =       103,
  pages =        107189,
  year =         2020,
  issn =         {0031-3203},
  doi =          {https://doi.org/10.1016/j.patcog.2019.107189},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0031320319304893},
  author =       {Lucas C. Ribas and Jarbas Joaci de Mesquita {SÁ
                  JÚNIOR} and Leonardo F. S. Scabini and Odemir
                  M. Bruno},
  keywords =     {Randomized neural networks, Complex networks,
                  Texture analysis, Feature extraction},
  abstract =     {This paper presents a high discriminative texture
                  analysis method based on the fusion of complex
                  networks and randomized neural networks. In this
                  approach, the input image is modeled as a complex
                  network and its topological properties as well as
                  the image pixels are used to train randomized neural
                  networks to create a signature that represents the
                  deep characteristics of the texture. The results
                  obtained surpassed the accuracy of many methods
                  available in the literature. This performance
                  demonstrates that our proposed approach opens a
                  promising source of research, which consists of
                  exploring the synergy of neural networks and complex
                  networks in the texture analysis field.}
}

%%%
% Exemplos de referências podem ser encontrados em: https://verbosus.com/bibtex-style-examples.html

@book{vapnik1995,
  author =       {Vapnik, Vladimir N.},
  biburl =
                  {https://www.bibsonomy.org/bibtex/2df9b1e85d80b3e3a448fc6c93e7051a0/tomhanika},
  isbn =         {0-387-94559-8},
  publisher =    {Springer-Verlag New York, Inc.},
  title =        {The nature of statistical learning theory},
  year =         1995,
  pages =        169
}

@article{ComplexNetworksSurvey2007,
  doi =          {10.1080/00018730601170527},
  url =          {https://doi.org/10.1080%2F00018730601170527},
  year =         2007,
  month =        {jan},
  publisher =    {Informa {UK} Limited},
  volume =       56,
  number =       1,
  pages =        {167--242},
  author =       {L. da F. Costa and F. A. Rodrigues and G. Travieso
                  and P. R. Villas Boas},
  title =        {Characterization of complex networks: A survey of
                  measurements},
  journal =      {Advances in Physics}
}

@InProceedings{ComplexNetworksImageClassification2015,
  author =       "de Lima, Geovana V. L.  and Castilho, Thullyo R.
                  and Bugatti, Pedro H.  and Saito, Priscila T. M.
                  and Lopes, Fabr{\'i}cio M.",
  editor =       "Pardo, Alvaro and Kittler, Josef",
  title =        "A Complex Network-Based Approach to the Analysis and
                  Classification of Images",
  booktitle =    "Progress in Pattern Recognition, Image Analysis,
                  Computer Vision, and Applications",
  year =         2015,
  publisher =    "Springer International Publishing",
  address =      "Cham",
  pages =        "322--330",
  abstract =     "Complex network is a topic related with a plurality
                  of knowledge from various areas and has been applied
                  with success in all of them. However, it is a recent
                  area considering its application in image pattern
                  recognition. There are few works in the literature
                  that use the complex networks for image
                  characterization following its analysis and
                  classification. An image can be interpreted as a
                  complex network wherein each pixel represents a
                  vertex and the weighted edges are generated
                  according to the location and intensity between two
                  pixels. Thus, the present paper aims to investigate
                  this type of application and explore different
                  measurements that can be extracted from complex
                  networks to better characterize an image. One
                  special type of measure that we applied were those
                  based on motifs, which are employed in several
                  areas. However, to the best of our knowledge, motifs
                  were never explored in complex networks representing
                  images. The results demonstrate that our proposed
                  methodology presented great potential, reaching up
                  to 89.81{\%} of accuracy for the classification of
                  public domain image texture datasets.",
  isbn =         "978-3-319-25751-8",
  volume =       9423
}

@inproceedings{matrizcoocorrencia2017,
  author =       {Ilea, Ioana and Bombrun, Lionel and Said, Salem and
                  Berthoumieu, Yannick},
  year =         2017,
  month =        10,
  pages =        {736-744},
  title =        {Co-occurrence Matrix of Covariance Matrices: A Novel
                  Coding Model for the Classification of Texture
                  Images},
  isbn =         {978-3-319-68444-4},
  doi =          {10.1007/978-3-319-68445-1_85}
}

@inproceedings{rezatofighi2019generalized,
  title =        {Generalized intersection over union: A metric and a
                  loss for bounding box regression},
  author =       {Rezatofighi, Hamid and Tsoi, Nathan and Gwak,
                  JunYoung and Sadeghian, Amir and Reid, Ian and
                  Savarese, Silvio},
  booktitle =    {Proceedings of the IEEE/CVF conference on computer
                  vision and pattern recognition},
  pages =        {658--666},
  year =         2019
}

@inproceedings{duchenne2008segmentation,
  title =        {Segmentation by transduction},
  author =       {Duchenne, Olivier and Audibert, Jean-Yves and
                  Keriven, Renaud and Ponce, Jean and S{\'e}gonne,
                  Florent},
  booktitle =    {2008 IEEE conference on computer vision and pattern
                  recognition},
  pages =        {1--8},
  year =         2008,
  organization = {IEEE}
}

@article{shan2023interactive,
  title =        {Interactive image segmentation based on multi-layer
                  random forest classifiers},
  author =       {Shan, Yilin and Ma, Yan and Liao, Yuan and Huang,
                  Hui and Wang, Bin},
  journal =      {Multimedia Tools and Applications},
  volume =       82,
  number =       15,
  pages =        {22469--22495},
  year =         2023,
  publisher =    {Springer}
}

@article{ramadan2020survey,
  title =        {A survey of recent interactive image segmentation
                  methods},
  author =       {Ramadan, Hiba and Lachqar, Chaymae and Tairi, Hamid},
  journal =      {Computational visual media},
  volume =       6,
  pages =        {355--384},
  year =         2020,
  publisher =    {Springer}
}

% nesse artigo tem a imagem visualmente explicando IoU and Dice/F1 (metrics.jpg)

@Article{maxwell2021metrics,
  AUTHOR =       {Maxwell, Aaron E. and Warner, Timothy A. and
                  GuillÉn, Luis Andrés},
  TITLE =        {Accuracy Assessment in Convolutional Neural
                  Network-Based Deep Learning Remote Sensing
                  Studies—Part 1: Literature Review},
  JOURNAL =      {Remote Sensing},
  VOLUME =       13,
  YEAR =         2021,
  NUMBER =       13,
  ARTICLE-NUMBER =2450,
  URL =          {https://www.mdpi.com/2072-4292/13/13/2450},
  ISSN =         {2072-4292},
  ABSTRACT =     {Convolutional neural network (CNN)-based deep
                  learning (DL) is a powerful, recently developed
                  image classification approach. With origins in the
                  computer vision and image processing communities,
                  the accuracy assessment methods developed for
                  CNN-based DL use a wide range of metrics that may be
                  unfamiliar to the remote sensing (RS) community. To
                  explore the differences between traditional RS and
                  DL RS methods, we surveyed a random selection of 100
                  papers from the RS DL literature. The results show
                  that RS DL studies have largely abandoned
                  traditional RS accuracy assessment terminology,
                  though some of the accuracy measures typically used
                  in DL papers, most notably precision and recall,
                  have direct equivalents in traditional RS
                  terminology. Some of the DL accuracy terms have
                  multiple names, or are equivalent to another
                  measure. In our sample, DL studies only rarely
                  reported a complete confusion matrix, and when they
                  did so, it was even more rare that the confusion
                  matrix estimated population properties. On the other
                  hand, some DL studies are increasingly paying
                  attention to the role of class prevalence in
                  designing accuracy assessment approaches. DL studies
                  that evaluate the decision boundary threshold over a
                  range of values tend to use the precision-recall
                  (P-R) curve, the associated area under the curve
                  (AUC) measures of average precision (AP) and mean
                  average precision (mAP), rather than the traditional
                  receiver operating characteristic (ROC) curve and
                  its AUC. DL studies are also notable for testing the
                  generalization of their models on entirely new
                  datasets, including data from new areas, new
                  acquisition times, or even new sensors.},
  DOI =          {10.3390/rs13132450}
}

@article{wang2023review,
  title =        {Review of GrabCut in Image Processing},
  author =       {Wang, Zhaobin and Lv, Yongke and Wu, Runliang and
                  Zhang, Yaonan},
  journal =      {Mathematics},
  volume =       11,
  number =       8,
  pages =        1965,
  year =         2023,
  publisher =    {MDPI}
}

@article{rother2004grabcut,
  title =        {GrabCut: interactive foreground extraction using
                  iterated graph cuts},
  author =       {Rother, Carsten and Kolmogorov, Vladimir and Blake,
                  Andrew},
  journal =      {ACM transactions on graphics (TOG)},
  volume =       23,
  number =       3,
  pages =        {309--314},
  year =         2004,
  publisher =    {ACM New York, NY, USA}
}

@inproceedings{an2013iterated,
  title =        {Iterated graph cut integrating texture
                  characterization for interactive image segmentation},
  author =       {An, Ning-Yu and Pun, Chi-Man},
  booktitle =    {2013 10th International Conference Computer
                  Graphics, Imaging and Visualization},
  pages =        {79--83},
  year =         2013,
  organization = {IEEE}
}

@inproceedings{schick2012measuring,
  title =        {Measuring and evaluating the compactness of
                  superpixels},
  author =       {Schick, Alexander and Fischer, Mika and
                  Stiefelhagen, Rainer},
  booktitle =    {Proceedings of the 21st international conference on
                  pattern recognition (ICPR2012)},
  pages =        {930--934},
  year =         2012,
  organization = {IEEE}
}

% para citar sobre gabor filters e matriz de co-ocorrencias

@inproceedings{kumar2014detailed,
  title =        {A detailed review of feature extraction in image
                  processing systems},
  author =       {Kumar, Gaurav and Bhatia, Pradeep Kumar},
  booktitle =    {2014 Fourth international conference on advanced
                  computing \& communication technologies},
  pages =        {5--12},
  year =         2014,
  organization = {IEEE}
}

% para citar imagem sobre manhattan vs euclidean

@Inbook{Singh2019,
  author =       "Singh, Himanshu",
  title =        "Image Processing Using Machine Learning",
  bookTitle =    "Practical Machine Learning and Image Processing: For
                  Facial Recognition, Object Detection, and Pattern
                  Recognition Using Python",
  year =         2019,
  publisher =    "Apress",
  address =      "Berkeley, CA",
  pages =        "89--132",
  abstract =     "We start this chapter by examining a few of the most
                  widely used image processing algorithms, then move
                  on to machine learning implementation in image
                  processing. The chapter at a glance is as follows:",
  isbn =         "978-1-4842-4149-3",
  doi =          "10.1007/978-1-4842-4149-3_5",
  url =          "https://doi.org/10.1007/978-1-4842-4149-3_5"
}

% imagem sobre filtros de gabor

@inproceedings{Kmrinen2012GaborFI,
  title =        {Gabor features in image analysis},
  author =       {Joni-Kristian K{\"a}m{\"a}r{\"a}inen},
  booktitle =    {International Conference on Image Processing Theory
                  Tools and Applications},
  year =         2012,
  url =          {https://api.semanticscholar.org/CorpusID:14909537}
}

@inproceedings{chen2022focalclick,
  title =        {Focalclick: Towards practical interactive image
                  segmentation},
  author =       {Chen, Xi and Zhao, Zhiyan and Zhang, Yilei and Duan,
                  Manni and Qi, Donglian and Zhao, Hengshuang},
  booktitle =    {Proceedings of the IEEE/CVF Conference on Computer
                  Vision and Pattern Recognition},
  pages =        {1300--1309},
  year =         2022
}

@article{feng2021review,
  title =        {A review and comparative study on probabilistic
                  object detection in autonomous driving},
  author =       {Feng, Di and Harakeh, Ali and Waslander, Steven L
                  and Dietmayer, Klaus},
  journal =      {IEEE Transactions on Intelligent Transportation
                  Systems},
  volume =       23,
  number =       8,
  pages =        {9961--9980},
  year =         2021,
  publisher =    {IEEE}
}

@inproceedings{zhou2019interactive,
  title =        {Interactive deep editing framework for medical image
                  segmentation},
  author =       {Zhou, Bowei and Chen, Li and Wang, Zhao},
  booktitle =    {Medical Image Computing and Computer Assisted
                  Intervention--MICCAI 2019: 22nd International
                  Conference, Shenzhen, China, October 13--17, 2019,
                  Proceedings, Part III 22},
  pages =        {329--337},
  year =         2019,
  organization = {Springer}
}

@article{sah2020machine,
  doi =          {10.20944/preprints202007.0230.v1},
  url =          {https://doi.org/10.20944/preprints202007.0230.v1},
  year =         2020,
  month =        {July},
  publisher =    {Preprints},
  author =       {Shagan Sah},
  title =        {Machine Learning: A Review of Learning Types},
  journal =      {Preprints}
}

@techreport{achanta2010slic,
  title =        {SLIC superpixels},
  author =       {Achanta, Radhakrishna and Shaji, Appu and Smith,
                  Kevin and Lucchi, Aurelien and Fua, Pascal and
                  S{\"u}sstrunk, Sabine},
  year =         2010,
  urlaccessdate ={25 nov. 2023},
  url =
                  {https://www.epfl.ch/labs/ivrl/research/slic-superpixels/},
}

@article{haralick1979statistical,
  title =        {Statistical and structural approaches to texture},
  author =       {Haralick, Robert M},
  journal =      {Proceedings of the IEEE},
  volume =       67,
  number =       5,
  pages =        {786--804},
  year =         1979,
  publisher =    {IEEE}
}

@article{daugman1988complete,
  title =        {Complete discrete 2-D Gabor transforms by neural
                  networks for image analysis and compression},
  author =       {Daugman, John G},
  journal =      {IEEE Transactions on acoustics, speech, and signal
                  processing},
  volume =       36,
  number =       7,
  pages =        {1169--1179},
  year =         1988,
  publisher =    {IEEE}
}

@article{scikit-image,
  title =        {scikit-image: image processing in {P}ython},
  author =       {van der Walt, {S}t\'efan and {S}ch\"onberger,
                  {J}ohannes {L}. and {Nunez-Iglesias}, {J}uan and
                  {B}oulogne, {F}ran\c{c}ois and {W}arner, {J}oshua
                  {D}. and {Y}ager, {N}eil and {G}ouillart,
                  {E}mmanuelle and {Y}u, {T}ony and the scikit-image
                  contributors},
  year =         2014,
  month =        6,
  keywords =     {Image processing, Reproducible research, Education,
                  Visualization, Open source, Python, Scientific
                  programming},
  volume =       2,
  pages =        {e453},
  journal =      {PeerJ},
  issn =         {2167-8359},
  url =          {https://doi.org/10.7717/peerj.453},
  doi =          {10.7717/peerj.453}
}

@article{achanta2012slic,
  title =        {SLIC Superpixels Compared to State-of-the-art
                  Superpixel Methods},
  author =       {Achanta, Radhakrishna and Shaji, Appu and Smith,
                  Kevin and Lucchi, Aurélien and Fua, Pascal and
                  Süsstrunk, Sabine},
  publisher =    {Institute of Electrical and Electronics Engineers},
  journal =      {IEEE Transactions on Pattern Analysis and Machine
                  Intelligence},
  address =      {Los Alamitos},
  number =       11,
  volume =       34,
  pages =        {8. 2274-2282},
  year =         2012,
  abstract =     {Computer vision applications have come to rely
                  increasingly on superpixels in recent years, but it
                  is not always clear what constitutes a good
                  superpixel algorithm.  In an effort to understand
                  the benefits and drawbacks of existing methods, we
                  empirically compare five state-of-the-art superpixel
                  algorithms for their ability to adhere to image
                  boundaries, speed, memory efficiency, and their
                  impact on segmentation performance. We then
                  introduce a new superpixel algorithm, simple linear
                  iterative clustering (SLIC), which adapts a k-means
                  clustering approach to efficiently generate
                  superpixels. Despite its simplicity, SLIC adheres to
                  boundaries as well as or better than previous
                  methods. At the same time, it is faster and more
                  memory efficient, improves segmentation performance,
                  and is straightforward to extend to supervoxel
                  generation.},
  url =          {http://infoscience.epfl.ch/record/177415},
  doi =          {https://doi.org/10.1109/TPAMI.2012.120},
}

@article{samuel1959some,
  title =        {Some studies in machine learning using the game of
                  checkers},
  author =       {Samuel, Arthur L},
  journal =      {IBM Journal of research and development},
  volume =       3,
  number =       3,
  pages =        {210--229},
  year =         1959,
  publisher =    {IBM}
}

@misc{press2021machine,
  title =        {On thinking machines, machine learning, and how AI
                  took over statistics},
  url =
                  {https://www.forbes.com/sites/gilpress/2021/05/28/on-thinking-machines-machine-learning-and-how-ai-took-over-statistics/?sh=6056f4692513},
  journal =      {Forbes},
  publisher =    {Forbes Magazine},
  author =       {Press, Gil},
  year =         2021,
  month =        {May},
  urlaccessdate = {05 dez. 2023},
}
