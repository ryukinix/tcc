\chapter{FUNDAMENTAÇÃO TEÓRICA}\label{cap:fundamentacao-teorica}


Detalhar o overview da fundamentação teórica com a motivação principal
de todas as explicações


\section{Segmentação interativa de imagens}\label{sec:segmentacao-interativa}

A segmentação interativa de imagens é um processo de divisão de uma
imagem digital em várias partes ou regiões, geralmente para tornar a
imagem mais fácil de analisar e processar~\cite{ramadan2020survey}. Este processo é `interativo'
porque envolve a entrada do usuário para ajudar a orientar ou refinar
o processo de segmentação.

\begin{figure}[h!]
        \captionsetup{width=12cm}
		\Caption{\label{fig:interactive-segmentation}
          O usuário marca anotações do fundo e do objeto a ser
          segmentado, então a segmentação interativa é realizada.
        }
		\centering
		\UFCfig{}{\fbox{\includegraphics[width=12cm]{figuras/interactive-segmentation-2008}}}{\Fonte{\cite{duchenne2008segmentation}}}
\end{figure}
\FloatBarrier{}

De acordo com a figura~\ref{fig:interactive-segmentation}, na
segmentação interativa de imagens, o usuário pode selecionar regiões
de interesse, definir marcadores ou fazer anotações na imagem. Essas
entradas do usuário são então usadas para informar o algoritmo de
segmentação sobre como dividir a imagem. Por exemplo, o usuário pode
desenhar uma linha ao redor de um objeto de interesse, e o algoritmo
de segmentação irá então tentar dividir a imagem de tal forma que o
objeto de interesse seja isolado em sua própria região.

Este tipo de segmentação de imagem é útil em uma variedade de
aplicações, incluindo processamento de imagens médicas, visão
computacional, reconhecimento de padrões e muitos outros campos onde é
útil poder dividir uma imagem em regiões distintas com base em
critérios definidos pelo usuário.

\section{Aprendizado semi-supervisionado vs.\ transdução}\label{sec:teorica-aprendizado-semi-supervisionado}

Existem três principais categorias de aprendizado de máquina:
aprendizado supervisionado, aprendizado não-supervisionado e
aprendizado semi-supervisionado. No aprendizado supervisionado durante
a etapa de treinamento existe uma base de dados totalmente rotulada,
no aprendizado não-supervisionado não é disponibilizado nenhum
rotulamento dos dados. Enquanto isso, o aprendizado
semi-supervisionado está entre essas duas categorias.

O aprendizado semi-supervisionado é um método de aprendizado de máquina
que envolve o uso de um grande volume de dados não rotulados e um
pequeno volume de dados rotulados para treinar modelos de aprendizado
de máquina.

Formalmente, pode-se definir o aprendizado semi-supervisionado da seguinte maneira:

\begin{quote}
  Dado um conjunto de dados de treinamento
  $ \mathbf{X} = \{\vec{x_1}, \vec{x_2}, \ldots, \vec{x_n}\} $, tal que $ \vec{x_n} \in \mathbb{R}^d $,
  onde apenas um subconjunto  $ \vec{Y} = \{y_1, y_2, \ldots , y_m\} $ em que $ (m < n) $ tem rótulos
  correspondentes, o objetivo do aprendizado semi-supervisionado é usar
  tanto o conjunto de dados rotulado quanto o não rotulado para aprender
  a função $ f: \mathbf{X} \rightarrow \vec{Y} $ que pode prever o rótulo $ y $ para um novo
  exemplo $ \vec{x} $.
\end{quote}

O aprendizado semi-supervisionado é baseado na suposição de que os
dados não rotulados podem fornecer informações adicionais que podem
ser usadas para melhorar a precisão do modelo de aprendizado de
máquina. Isso é feito através de várias técnicas, como a propagação de
rótulos, onde os rótulos são propagados dos dados rotulados para os
dados não rotulados, ou a aprendizagem auto-supervisionada, onde o
modelo é treinado para prever partes dos dados a partir de outras
partes.

Por outro lado, existe um diferente tipo de aprendizado
semi-supervisionado que não realiza a etapa de estimar a função $ f
$. Algoritmos que estimam essa função são descritos como indutivos,
pois após o treinamento, para classificar novos dados, realizam uma
inferência por indução ao aplicar a função estimada.

Em contraponto, existem algoritmos que não estimam tal função e apenas
realizam a inferência direta entre os dados rotulados disponíveis e os
não rotulados. Isso é chamado de transdução e um algoritmo bem
conhecido com essa característica é o classificador K-NN.\@ Na
figura~\ref{fig:induction-vs-transduction} a seguir, é ilustrado as
diferenças entre transdução e indução no processo de aprendizagem:


\begin{figure}[h!]
        \captionsetup{width=12cm}
		\Caption{\label{fig:induction-vs-transduction}
          No aprendizado transdutivo, a inferência em novos exemplos
          ocorre de maneira direta.
        }
		\centering
		\UFCfig{}{\fbox{\includegraphics[width=12cm]{figuras/induction_vs_transduction}}}{\Fonte{\cite{vapnik1995}}}
\end{figure}


No texto~\cite{vapnik2006semi}, o criador do famoso algoritmo SVM,
estabelece uma profunda formalização dos problemas de aprendizado
semi-supervisionado e inferência transdutiva. No final do texto, ele declara
algumas reflexões sobre a solução de problemas em aprendizagem de
máquina. Em uma delas, ele diz que ao resolver um problema, não tente
resolve o problema geral como um passo intermediário, tente obter a
resposta que você precisa, mas não a mais geral. Por fim, um Vapnik
deixa uma sugestão relevante:


\begin{displayquote}

  Do not estimate a function if you need to estimate values at given
  points. (Try to perform transduction, not induction.)

\end{displayquote}

Em tradução-livre: \blockquote{Não estime uma função se você precisa estimar
os valores em dados pontos. (Tente executar transdução, não
indução)}. Essa sugestão é uma evidência que reforça a motivação
deste trabalho. Ao desenvolver um algoritmo transdutivo pra
segmentação de imagens de maneira assistida, não é estimado uma função
geral como um passo intermediário, mas a segmentação é realizada
diretamente baseado nas rotulações iniciais que o usuário forneceu.


\section{Superpixels}\label{sec:teorica-superpixel}

Superpixels fazem parte de um grupo de algoritmos de clusterização em
processamento de imagens que ganhou popularidade nos últimos anos na
comunidade de visão computacional~\cite{SuperpixelSurvey2020}. Em vez
de processar uma imagem pixel por pixel, agrupa-se pixels vizinhos
semelhantes em uma entidade maior, conhecida como superpixel.

O conceito de superpixels foi introduzido para superar as limitações
do processamento pixel a pixel, que não leva em consideração a
estrutura global da imagem. Os superpixels, por outro lado, mantêm a
estrutura da imagem e reduzem a complexidade do processamento de
imagens, tornando-o mais eficiente.

Os superpixels são formados com base na similaridade dos pixels em
termos de cor, intensidade e localização na imagem. Eles são usados em
uma variedade de aplicações, incluindo segmentação de imagem,
rastreamento de objetos, reconhecimento de objetos, entre outros.

Em resumo, os superpixels são uma técnica eficaz para simplificar a
representação de uma imagem e aumentar a eficiência do processamento
de imagens, mantendo a informação visual importante.

Atualmente, já é possível encontrar muitas técnicas baseado em
superpixels com diferentes características, complexidade
computacionais, eficiência e método. No
artigo~\cite{SuperPixelBenchmark2017}, é realizado um benchmark com 15
algoritmos superpixels categorizados em três grupos: basedo em grafos,
baseado em otimização de gradiente e baseado em análise de
textura. Nesse trabalho, é selecionado um dos mais simples: \gls{SLIC}.

\subsection{SLIC}\label{sec:teorica-superpixel-slic}


O algoritmo \gls{SLIC} é um método para segmentação de imagens baseado
em superpixel, é um dos mais simples e pode ser visto como uma
variação do algoritmo de clusterização k-means expandindo o espaço
euclidiano ao incluir também o espaço de cores. Ele divide uma imagem
em segmentos menores, chamados superpixels, que compartilham
características semelhantes, como cor e textura.

Uma explicação passo-a-passo de como o SLIC funciona pode ser entendida
dessa maneira:

\begin{algorithm}[h!]
	\SetSpacedAlgorithm{}
	\caption{\label{alg:slic} SLIC}
	\Entrada{Imagem a ser segmentada}
    \Resultado{Matriz de superpixels}
	\Inicio{
      \begin{enumerate}

      \item \textbf{Inicialização}: O algoritmo começa selecionando alguns pixels na
        imagem como centros de superpixels. Esses centros são espaçados
        uniformemente pela imagem;

      \item \textbf{Atribuição}: Em seguida, para cada pixel na imagem, o algoritmo
        calcula a distância entre esse pixel e todos os centros de
        superpixels. A distância é calculada com base na cor (ou intensidade
        de cinza para imagens em preto e branco) e na proximidade espacial. O
        pixel é então atribuído ao superpixel cujo centro está mais próximo;

      \item \textbf{Atualização}: Depois que todos os pixels foram atribuídos a um
        superpixel, o algoritmo recalcula os centros de superpixels como a
        média de todos os pixels dentro de cada superpixel;

      \item O processo de atribuição e atualização é repetido várias vezes
        até que o algoritmo alcance a condição de convergência, ou seja, até
        que os centros de superpixels parem de mudar significativamente;

      \item O resultado final é uma segmentação da imagem em superpixels, onde
        cada superpixel é um grupo de pixels com características semelhantes.
    \end{enumerate}
   }
\end{algorithm}


Uma execução do SLIC é possível de ser visualizada a seguir:

\begin{figure}[h!]
        \captionsetup{width=12cm}
		\Caption{\label{fig:slic}
          Execução do algoritmo SLIC na fotografia de um gato.
        }
		\centering
		\UFCfig{}{\fbox{\includegraphics[width=12cm]{figuras/slic}}}{\Fonte{\fonteautor}}
\end{figure}

O algoritmo \gls{SLIC} possuí três hiperparâmetros: \textit{segments}, sigma e \textit{compactness}.

\begin{enumerate}
\item \textbf{Segments}: Número de superpixels que será usado para
  segmentar a imagem.
\item \textbf{Sigma}: Este parâmetro é usado para suavizar a imagem antes da
segmentação. Um valor maior de sigma resultará em uma imagem mais
suave, o que pode ajudar a reduzir o ruído e os detalhes finos. No
entanto, um valor muito alto pode resultar em perda de detalhes
importantes.
\item \textbf{Compactness} Este parâmetro controla o equilíbrio entre a coerência
de cor e a proximidade espacial na formação de superpixels. Um valor
maior de compactness fará com que os superpixels sejam mais
quadrados, enquanto um valor menor fará com que os superpixels
sigam mais de perto os limites da imagem. Portanto, a compactness pode
ser ajustada para obter superpixels que são mais representativos da
estrutura da imagem.
\end{enumerate}


\section{Geração de redes complexas}\label{sec:teorica-redes-complexas}

Redes complexas são grafos de alta complexidade. Existem variados
algoritmos para geração de redes complexas
~\cite{ComplexNetworksSurvey2007}. Redes complexas podem ser usadas
como um domínio de dados para realizar tarefas como classificação de
imagens~\cite{ComplexNetworksImageClassification2015}, segmentação de
imagens, identificação de comunidades e também extração de
características~\cite{JarbasComplexNetworks2020}.

Neste trabalho, o uso de redes complexas é realizado de uma maneira
acoplada ao algoritmo de clusterização inicial da imagem (superpixel). Nesse
cenário, cada superpixel gerado na imagem é um vértice e as arestas
são gerados baseado na vizinhança.

Apesar de considerar o tema como redes complexas, esse cenário em
particular gera um grafo planar pela maneira como as arestas são
criadas. Por outro lado, seria possível também modificar a geração da
rede complexa para considerar as arestas do grafo baseado num raio
parametrizado de superpixel em relação a um \textit{treshrold} e
selecionar as k-nn similares como arestas válidas.

Essa etapa de geração da rede complexa é crucial para a execução da
dinâmica coletiva explorada na seção~\ref{sec:teorica-lcu}. Um dos
pontos centrais desse trabalho. Na figura~\ref{fig:complex-networks},
um exemplo de geração de rede complexa é apresentado conectado com a
ilustração~\ref{fig:slic}, ao executar o algoritmo SLIC.\@

\begin{figure}[t]
        \captionsetup{width=12cm}
		\Caption{\label{fig:complex-networks}
          Geração de rede complexa baseado nos superpixels.
        }
		\centering
		\UFCfig{}{\fbox{\includegraphics[width=12cm]{figuras/complex-networks}}}{\Fonte{\fonteautor}}
\end{figure}
\FloatBarrier{}

\section{Extração de características}\label{sec:extracao-caracteristicas}

\subsection{Matriz de co-ocorrências}\label{sec:teorica-matriz-co-ocorrencia}

O método de extração de características da matriz de co-ocorrências é
uma técnica utilizada em processamento de imagem e visão computacional
para extrair características texturais de uma imagem~\cite{matrizcoocorrencia2017}.

Formalmente, uma matriz de co-ocorrência C é definida sobre uma imagem
I, para um deslocamento $\Delta x, \Delta y$, como:

\begin{equation}\label{eq:comatrix}
  C_{\Delta x, \Delta y}(i,j) = \sum_{x=1}^n\sum_{y=1}^m
  \begin{cases} 1, & \text{if }I(x,y)=i\text{ e }I(x+\Delta x, y+\Delta y)=j
               \\ 0, & \text{caso contrário}
  \end{cases}
\end{equation}

Na equação~\ref{eq:comatrix} $C_{\Delta x, \Delta y}(i,j)$ é o número de vezes
que o par de pixels com intensidades i e j ocorre em dois pixels
separados pelas distâncias (horizontal e vertical) na imagem I.

A matriz de co-ocorrência é tipicamente normalizada dividindo cada
elemento pelo número total de pares de pixels na imagem, resultando em
uma matriz de probabilidade de co-ocorrência.

A partir desta matriz, várias características texturais podem ser
extraídas, como contraste, correlação, energia e homogeneidade. Estas
características podem ser usadas para tarefas como classificação de
textura, segmentação de imagem, entre outros.

\subsection{Filtros de gabor}\label{sec:filtros-gabor}

Escrever sobre métodos de extração de característica via filtros de gabor.

\section{Métricas de similaridade}\label{sec:teorica-metricas-de-similaridade}


Métricas de similaridade neste trabalho são calculadas com o propósito
de comparar a similaridade entre os vetores de características dos
superpixels. Para as técnicas de extração de características descritas
na seção~\ref{sec:extracao-caracteristicas}, cada técnica se comportou
melhor com uma métrica de similaridade diferente.

Uma função de similaridade entre dois vetores de características
retorna um valor maior quando os vetores são similares e quanto mais
diferentes sejam, a similaridade tende a zero.

A estrutura de uma métrica de similaridade pode ser criada a partir de
uma métrica de distância. Neste trabalho, é explorado duas métricas de
similaridades a partir das seguintes métricas de distância: distância
euclidiana e distância de manhattan.

A distância euclidiana é o módulo da reta que conecta dois pontos no
espaço. A distância de manhattan é a soma da diferença absoluta entre
dois pontos para cada dimensão. Na figura
\ref{fig:manhattan-vs-euclidean}, é ilustrado atavés de duas figuras
em que são dispostos dois pontos $ x $ e $ y $ no espaço euclidiano
com os módulos de reta usados para compor a distância de cada métrica.

\begin{figure}[!h]
        \captionsetup{width=8cm}
		\Caption{\label{fig:manhattan-vs-euclidean}
          Visualização da distância de manhattan e distância euclidiana.
        }
		\centering
		\UFCfig{}{\fbox{\includegraphics[width=8cm]{figuras/manhattan-vs-euclidean}}}{\Fonte{\cite{Singh2019}}}
\end{figure}
\FloatBarrier{}

Para as equações das distâncias, tem-se a seguinte equação para a
distância euclidiana:

\begin{equation}\label{eq:euclidian-distance}
ed(\vec{x}, \vec{y}) = \sqrt{{(y_1-x_1)}^2 + {(y_2-x_2)}^2 + \ldots + {(y_n-x_n)}^2}
\end{equation}

Para a distância de manhattan, tem-se a seguinte equação:

\begin{equation}\label{eq:manhattan-distance}
md(\vec{x}, \vec{y}) = |y_1-x_1| + |y_2-x_2| + \ldots + |y_n-x_n|
\end{equation}

\subsection{Similaridade Euclidiana Exponencial}\label{sec:teorica-similaridade-euclidiana}

Para a técnica de extração de característica de matrizes de co-ocorrência
detalhado na seção~\ref{sec:teorica-matriz-co-ocorrencia}, a métrica de
similaridade que foi obtido melhores resultados foi a distância
euclidiana pelo inverso da exponencial. A equação é definida como:

\begin{equation}\label{eq:euclidian-similarity}
  ed\_sim(\vec{x}, \vec{y}) = \dfrac{1}{e^{ed(\vec{x}, \vec{y})}}
\end{equation}

\subsection{Similaridade de Manhattan Logarítimica}\label{sec:teorica-similaridade-manhattan}

Para a técnica envolvendo filtros de gabor, a distância entre os
vetores de características tiveram valores tão altos que ao usar a
similaridade euclidiana (exponencial ou não), maior parte dos valores
chegavam a zero. Por esse motivo, o uso da conversão para o domínio
logarítimico foi usado para suavizar o crescimento exagerado dos
valores, obtendo bons resultados. A definição para essa equação de
similaridade segue a seguir:

\begin{equation}\label{eq:manhattan-similarity}
  md\_sim(\vec{x}, \vec{y}) = \dfrac{1}{1 + \ln(1 + md(\vec{x}, \vec{y}))}
\end{equation}

Na equação~\ref{eq:manhattan-similarity}, os valores 1 adicionados no demoninador foram feitos para evitar uma
possível divisão por zero e logarítmo de zero,
ambas operações que são indefinidas na matemática.


\section{LCU}\label{sec:teorica-lcu}

O algoritmo \gls{LCU} foi desenvolvido por um
brasileiro~\cite{VerriNetworkUnfoldingMap2018}, é uma dinâmica
coletiva baseado em propagação de rótulos numa rede complexa. Essa
dinâmica coletiva é modelada como um sistema dinâmico com geração de
partículas de rotulação nas suas fontes (os vértices rotulados).

Esse algoritmo possuem critérios de sobrevivência das particulas
inspirado em comportamentos da natureza e sociedade. Por exemplo, o
hiperparâmetro $ \lambda $ do algoritmo denota um fator de competição entre
0 e 1 sobre o dificuldade que as partículas terão ao trafegar nos
vértices, tornando a sobrevivência delas mais difícil ao percorrer o
grafo. Para esse parâmetro, 0 significa um passeio aleatório no grafo,
1 significa máxima competitividade. Embora as partículas nasçam nos
vértices, a competição por dominação acontece nas arestas. No final, o
vértice será marcado com o novo rótulo baseado no tipo de partícula
que mais conseguiu dominar arestas desse vértice.

Nesse caso particular, a implementação proposta neste trabalho é
ligeiramente diferente da proposta originalmente, pois a rede complexa
no cenário que o autor propõe as arestas não possuem peso. Uma
modificação é realizada para incluir a similaridade de imagem entre
dois superpixels, dessa maneira é criado um fator de aumento da
probabilidade das partículas visitarem os nós mais promissores
(texturas mais similares). Como discutido na seção
~\ref{sec:teorica-aprendizado-semi-supervisionado}, esse cenário de
aprendizado é semi-supervisionado transdutivo: poucos rótulos estão
disponíveis e nenhuma função de inferência é estimada. A inferência
acontece diretamente entre os pontos rótulados e os não-rotulados.


\begin{figure}[!h]
\centering
    \captionsetup{width=14cm}
    \Caption{\label{fig:lcu-execution}
      Rede complexa para execução da dinâmica \gls{LCU}. Anotação
      parcial em~(\subref{fig:lcu-partial}) e resultado final em~(\subref{fig:lcu-done})
    }

    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \UFCfig{}{\fbox{\includegraphics[width=7cm]{figuras/lcu-partial}}}
    \caption{\label{fig:lcu-partial}}
    \end{subfigure}
\quad
    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \UFCfig{}{\fbox{\includegraphics[width=7cm]{figuras/lcu-done}}}
    \caption{\label{fig:lcu-done}}
    \end{subfigure}
    {\Fonte{\fonteautor}}
\quad
\end{figure}
\FloatBarrier{}


Na figura~\ref{fig:lcu-execution},é possível ver a execução do
algoritmo numa rede complexa densa aleatória, no início há alguns
poucos vértices anotados em azul e vermelho. No final da execução os
rótulos são propagados semanticamente baseado na disputa entre as
partículas para dominar arestas, e por fim, marcar os vértices
dominados por aquela classe.


\section{EGSIS}\label{sec:teorica-egsis}

A ser escrito, algoritmo \gls{EGSIS} agregador que une todas as partes.
